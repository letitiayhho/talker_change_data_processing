---
title: "Average"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
setwd("/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("ggplot2")
library("ggpubr")
library("kableExtra")
library("tidyr")
source("tools/functions.R")
source("4_test_cross_correlations/src/functions.R")

# Param
ALT = 'two.sided' # 'greater' or 'two.sided'
NORM = "normalized_" # either "normalized_" or ""
```

```{r}
# Import data
xcorr <- read.csv(file = paste("3_cross_correlate/data/", NORM, "average.csv", sep = ''))
channels <- as.character(1:128)
subs <- as.character(unique(xcorr$subject_number))
n <- length(subs)
conds <- unique(c(xcorr$constraint, xcorr$meaning, xcorr$talker))
```

#### One-sample t-tests for overall tracking

```{r}
overall <- get_subject_averages(xcorr)
overall_w <- get_one_sample_wilcoxon_for_each_channel(overall, alt = ALT)

# Creating a table to display all the p-values
spacer <- matrix(" ", 128, 1)
overall_ps <- data.frame(channels, 'p'= overall_w$p)
map_df <- mutate_if(overall_ps, is.numeric, function(x) {round(x, digits = 3)}) %>%
  mutate_if(is.numeric, function(x) {ifelse(x > 0.1,
                                            cell_spec(x, NULL),
                                            cell_spec(x, background = spec_color(x,
                                                                                 direction = 1,
                                                                                 begin = 0.65,
                                                                                 end = 1,
                                                                                 option = "B",
                                                                                 scale_from = c(0,0.1))))})

kable(map_df, escape = F, col.names = c("Channel", "p")) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```


#### One-sample wilcoxon for each condition

Compares the cross correlations for each condition level (e.g. same-talker, meaningful) to 0.

```{r}
# Data frames will be named according to their condition, with the code for talker, then meaning, then constraint listed in that order
# Same-talker = S
# Different-talker = T
# Meaningful = M
# Nonsense = N
# Low constraint = L
# High constraint = H
S <- subset(xcorr, talker = "S") %>% get_subject_averages()
T <- subset(xcorr, talker = "T") %>% get_subject_averages()
M <- subset(xcorr, meaning = "M") %>% get_subject_averages()
N <- subset(xcorr, meaning = "N") %>% get_subject_averages()
L <- subset(xcorr, constraint = "L") %>% get_subject_averages()
H <- subset(xcorr, constraint = "H") %>% get_subject_averages()
```

```{r}
S_w <- get_one_sample_wilcoxon_for_each_channel(S, ALT)
T_w <- get_one_sample_wilcoxon_for_each_channel(T, ALT)
M_w <- get_one_sample_wilcoxon_for_each_channel(M, ALT)
N_w <- get_one_sample_wilcoxon_for_each_channel(N, ALT)
L_w <- get_one_sample_wilcoxon_for_each_channel(L, ALT)
H_w <- get_one_sample_wilcoxon_for_each_channel(H, ALT)
```

```{r}
# Creating a table to display all the p-values
one_sample_w <- data.frame(channels, 
                     'S' = S_w$p,
                     'T' = T_w$p, 
                     'M' = M_w$p,
                     'N' = N_w$p, 
                     'L' = L_w$p,
                     'H' = H_w$p)
map_df <- mutate_if(one_sample_w, is.numeric, function(x) {round(x, digits = 3)}) %>%
  mutate_if(is.numeric, function(x) {ifelse(x > 0.1, 
                                            cell_spec(x, NULL),
                                            cell_spec(x, background = spec_color(x, 
                                                                                 direction = 1, 
                                                                                 begin = 0.65, 
                                                                                 end = 1, 
                                                                                 option = "B", 
                                                                                 scale_from = c(0,0.1))))})

kable(map_df, escape = F, col.names = c("Channel", "S", "T", "M", "N", "S", "G")) %>%
  add_header_above(c(" " = 1, "Talker" = 2, "Meaning" = 2, "Constraint" = 2)) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```


```{r}
sum(overall_w$p < 0.05)
sum(T_w$p < 0.05)
sum(S_w$p < 0.05)
sum(M_w$p < 0.05)
sum(N_w$p < 0.05)
sum(L_w$p < 0.05)
sum(H_w$p < 0.05)
```

#### Two-sample Wilcoxon

Compares cross correlations between the two levels of each condition. 

```{r}
talker_w <- get_two_sample_wilcoxon_for_each_channel(S, T, paired = TRUE)
meaning_w <- get_two_sample_wilcoxon_for_each_channel(M, N, paired = TRUE)
constraint_w <- get_two_sample_wilcoxon_for_each_channel(L, H, paired = TRUE)

talker_w$w_adjusted <-standardize_ws(talker_w$p, talker_w$w)
meaning_w$w_adjusted <-standardize_ws(meaning_w$p, meaning_w$w)
constraint_w$w_adjusted <-standardize_ws(constraint_w$p, constraint_w$w)
```

```{r}
# Creating a table to display all the p-values
two_sample_w <- data.frame(channels, 
                     'talker' = talker_w$p,
                     'meaning' = meaning_w$p,
                     'constraint' = constraint_w$p)
map_df <-  mutate_if(two_sample_w, is.numeric, function(x) {round(x, digits = 3)}) %>%
  mutate_if(is.numeric, function(x) {ifelse(x > 0.1, 
                                            cell_spec(x, NULL),
                                            cell_spec(x, background = spec_color(x, 
                                                                                 direction = 1, 
                                                                                 begin = 0.65, 
                                                                                 end = 1, 
                                                                                 option = "B", 
                                                                                 scale_from = c(0,0.1))))})

kable(map_df, escape = F, col.names = c("Channel", "Talker", "Meaning", "Constraint")) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

```{r}
sum(talker_w$p < 0.05)
sum(meaning_w$p < 0.05)
sum(constraint_w$p < 0.05)
```


#### Wilcoxon with interaction by constraint

```{r}
# Subset talker
SL <- subset(xcorr, talker = "S", constraint = "L") %>% get_subject_averages()
SH <- subset(xcorr, talker = "S", constraint = "H") %>% get_subject_averages()
TL <- subset(xcorr, talker = "T", constraint = "L") %>% get_subject_averages()
TH <- subset(xcorr, talker = "T", constraint = "H") %>% get_subject_averages()

# Subset meaning
ML <- subset(xcorr, meaning = "M", constraint = "L") %>% get_subject_averages()
MH <- subset(xcorr, meaning = "M", constraint = "H") %>% get_subject_averages()
NL <- subset(xcorr, meaning = "N", constraint = "L") %>% get_subject_averages()
NH <- subset(xcorr, meaning = "N", constraint = "H") %>% get_subject_averages()
```

```{r}
# One-sample t-tests for talker
SL_w <- get_one_sample_wilcoxon_for_each_channel(SL, ALT)
SH_w <- get_one_sample_wilcoxon_for_each_channel(SH, ALT)
TL_w <- get_one_sample_wilcoxon_for_each_channel(TL, ALT)
TH_w <- get_one_sample_wilcoxon_for_each_channel(TH, ALT)

# One-sample t-tests for meaning
ML_w <- get_one_sample_wilcoxon_for_each_channel(ML, ALT)
MH_w <- get_one_sample_wilcoxon_for_each_channel(MH, ALT)
NL_w <- get_one_sample_wilcoxon_for_each_channel(NL, ALT)
NH_w <- get_one_sample_wilcoxon_for_each_channel(NH, ALT)
```

```{r}
# One-sample t-tests for talker
SL_w$w_adjusted <-standardize_ws(SL_w$p, SL_w$w)
SH_w$w_adjusted <-standardize_ws(SH_w$p, SH_w$w)
TL_w$w_adjusted <-standardize_ws(TL_w$p, TL_w$w)
TH_w$w_adjusted <-standardize_ws(TH_w$p, SH_w$w)

# One-sample t-tests for meaning
ML_w$w_adjusted <-standardize_ws(ML_w$p, ML_w$w)
MH_w$w_adjusted <-standardize_ws(MH_w$p, MH_w$w)
NL_w$w_adjusted <-standardize_ws(NL_w$p, NL_w$w)
NH_w$w_adjusted <-standardize_ws(NH_w$p, NH_w$w)
```

```{r}
# Creating a table to display all the p-values
interaction_w <- data.frame(channels, 
                     'SL' = SL_w$p,
                     'SH' = SH_w$p,
                     'TL' = TL_w$p,
                     'TH' = TH_w$p, 
                     'ML' = ML_w$p,
                     'MH' = MH_w$p,
                     'NL' = NL_w$p,
                     'NH' = NH_w$p)
map_df <- mutate_if(interaction_w, is.numeric, function(x) {round(x, digits = 3)}) %>%
  mutate_if(is.numeric, function(x) {ifelse(x > 0.1, 
                                            cell_spec(x, NULL),
                                            cell_spec(x, background = spec_color(x, 
                                                                                 direction = 1, 
                                                                                 begin = 0.65, 
                                                                                 end = 1, 
                                                                                 option = "B", 
                                                                                 scale_from = c(0,0.1))))})

kable(map_df, escape = F, col.names = c("Channel", "L", "H", "L", "H", "L", "H", "L", "H")) %>%
  add_header_above(c(" " = 1, "Same-talker" = 2, "Different-talker" = 2, "Meaningful" = 2, "Nonsense" = 2)) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

```{r}
talker_L_w <- get_two_sample_wilcoxon_for_each_channel(SL, TL, paired = TRUE)
talker_H_w <- get_two_sample_wilcoxon_for_each_channel(SH, TH, paired = TRUE)
meaning_L_w <- get_two_sample_wilcoxon_for_each_channel(ML, NL, paired = TRUE)
meaning_H_w <- get_two_sample_wilcoxon_for_each_channel(MH, NH, paired = TRUE)

talker_L_w$w_adjusted <-standardize_ws(talker_L_w$p, talker_L_w$w)
talker_H_w$w_adjusted <-standardize_ws(talker_H_w$p, talker_H_w$w)
meaning_L_w$w_adjusted <-standardize_ws(meaning_L_w$p, meaning_L_w$w)
meaning_H_w$w_adjusted <-standardize_ws(meaning_H_w$p, meaning_H_w$w)
```

```{r}
# Creating a table to display all the p-values
interaction_two_sample_w <- data.frame(channels, 
                     'talker_L' = talker_L_w$p,
                     'talker_H' = talker_H_w$p,
                     'meaning_L' = meaning_L_w$p,
                     'meaning_H' = meaning_H_w$p)
map_df <- mutate_if(interaction_two_sample_w, is.numeric, function(x) {round(x, digits = 3)}) %>%
  mutate_if(is.numeric, function(x) {ifelse(x > 0.1, 
                                            cell_spec(x, NULL),
                                            cell_spec(x, background = spec_color(x, 
                                                                                 direction = 1, 
                                                                                 begin = 0.65, 
                                                                                 end = 1, 
                                                                                 option = "B", 
                                                                                 scale_from = c(0,0.1))))})

kable(map_df, escape = F, col.names = c("Channel", "L", "H", "L", "H")) %>%
  add_header_above(c(" " = 1, "Talker" = 2, "Meaning" = 2)) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

#### T-tests against difference set by low vs high-constraint sentences

```{r}
# SML <- subset(xcorr, talker = "S", meaning = "M", constraint = "L", keepLabels = TRUE)
# SML_means <- aggregate(SML[,2:129], by=list(SML$subject_number), FUN=mean) %>%
#   subset(-1)
```

```{r}
# take meaningful and same-talker sentences and compare correlations of low- vs high-constraint sentences
# compare this difference to meaningful and high-constraint same- vs different-talker sentences
# compare this difference to same-talker and high-constraint meaningful vs nonsense sentences
# SML <- subset(xcorr, talker = "S", meaning = "M", constraint = "L", keepLabels = TRUE)
# SML_means <- aggregate(SML[,5:132], by=list(SML$subject_number), FUN=mean) %>% select(-"Group.1")
# SMH <- subset(xcorr, talker = "S", meaning = "M", constraint = "H", keepLabels = TRUE)
# SMH_means <- aggregate(SMH[,5:132], by=list(SMH$subject_number), FUN=mean) %>% select(-"Group.1")
# baseline <- SMH_means - SML_means
# 
# TMH <- subset(xcorr, talker = "T", meaning = "M", constraint = "H", keepLabels = TRUE)
# TMH_means <- aggregate(TMH[,5:132], by=list(TMH$subject_number), FUN=mean) %>% select(-"Group.1")
# talker_compare <- TMH_means - SMH_means
# 
# SNH <- subset(xcorr, talker = "S", meaning = "N", constraint = "H", keepLabels = TRUE)
# SNH_means <- aggregate(SNH[,5:132], by=list(SNH$subject_number), FUN=mean) %>% select(-"Group.1")
# meaning_compare <- SNH_means - SMH_means
```

```{r}
# t-test by subject
# talker_compare_w <- get_two_sample_wilcoxon_for_each_channel(baseline, talker_compare)
# meaning_compare_w <- get_two_sample_wilcoxon_for_each_channel(baseline, meaning_compare)
```

```{r}
# Creating a table to display all the p-values
# compare_w <- data.frame(channels,
#                      'talker' = talker_compare_w$p,
#                      'meaning' = meaning_compare_w$p)
# map_df <- mutate_if(compare_w, is.numeric, function(x) {round(x, digits = 3)}) %>%
#   mutate_if(is.numeric, function(x) {ifelse(x > 0.1,
#                                             cell_spec(x, NULL),
#                                             cell_spec(x, background = spec_color(x,
#                                                                                  direction = 1,
#                                                                                  begin = 0.65,
#                                                                                  end = 1,
#                                                                                  option = "B",
#                                                                                  scale_from = c(0,0.1))))})
# 
# kable(map_df, escape = F, col.names = c("Channel", "Talker", "Meaning")) %>%
#   kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```


#### Plot test statistics

```{r}
# Plot p-values
hist(S_w$p, ylim = c(0,40))
hist(T_w$p, ylim = c(0,40))
hist(M_w$p, ylim = c(0,40))
hist(N_w$p, ylim = c(0,40))
hist(L_w$p, ylim = c(0,40))
hist(H_w$p, ylim = c(0,40))
```

```{r}
# Plot test statistics
standardize_ws <- function(p, w) {
  i <- which(p == max(p))
  mid <- w[i]
  w_adjusted <- abs(w - mid)
  return(w_adjusted)
}

get_critical_value <- function(p, w) {
  c <- min(w[which(p < 0.05)])
  return(c)
}

plot_ws <- function(w1, w2, labs, c, fname) {
  df_long <- data.frame(w1 = unlist(w1), w2 = unlist(w2)) %>%
    pivot_longer(cols = c("w1", "w2"),
                 names_to = "condition",
                 values_to = "W")
  p <- ggplot(df_long, aes(x = W, fill = condition)) +
    geom_histogram(position ="identity", alpha=0.65, bins = 15) +
    geom_vline(xintercept = c) +
    scale_fill_discrete(labels = labs) +
    scale_color_discrete(labels = labs) +
    ylim(c(0, 25)) +
    xlim(c(0, 35))
  ggsave(p, filename = fname, width = 6, height = 3.5)
  return(p)
}

overall_w$w_adjusted <- standardize_ws(overall_w$p, overall_w$w)
S_w$w_adjusted <- standardize_ws(S_w$p, S_w$w)
T_w$w_adjusted <- standardize_ws(T_w$p, T_w$w)
M_w$w_adjusted <- standardize_ws(M_w$p, M_w$w)
N_w$w_adjusted <- standardize_ws(N_w$p, N_w$w)
L_w$w_adjusted <- standardize_ws(L_w$p, L_w$w)
H_w$w_adjusted <- standardize_ws(H_w$p, H_w$w)

c <- get_critical_value(S_w$p, S_w$w_adjusted)

plot_ws(S_w$w_adjusted, T_w$w_adjusted, c("S", "T"), c, "4_test_cross_correlations/figs/ws_talker.png")
plot_ws(M_w$w_adjusted, N_w$w_adjusted, c("M", "N"), c, "4_test_cross_correlations/figs/ws_meaning.png")
plot_ws(L_w$w_adjusted, H_w$w_adjusted, c("L", "H"), c, "4_test_cross_correlations/figs/ws_constraint.png")
```

```{r}
p <- ggplot(overall_w, aes(x = w_adjusted)) +
    geom_histogram(position ="identity", alpha=0.8, bins = 15) +
    geom_vline(xintercept = c) +
    scale_fill_discrete(labels = labs) +
    scale_color_discrete(labels = labs) +
    ylim(c(0, 25)) +
    xlim(c(0, 35)) +
    xlab("w")
p 
ggsave(filename = "../figs/ws_overall.png", plot = p, width = 6, height = 2.5)
sum(overall_w$p < 0.05)
```


#### Plot cross correlations

```{r}
# Plot cross correlations for channels with significant cross correlations

get_sig_xcorrs <- function(xcorr, p) { # get xcorrs from sig channels
  sig_xcorr <- as.matrix(xcorr) %>%
   .[, which(p < 0.05)] %>%
    abs() %>%
    rowMeans() %>% # colMeans() compares channels, rowMeans() compares subs
    remove_outliers()
  return(sig_xcorr)
}

get_sig_xcorrs_df <- function(cond, group, sig_xcorr) {
  cond_col <- rep(cond, length(sig_xcorr))
  group_col <- rep(group, length(sig_xcorr))
  df <- data.frame(cond, sig_xcorr, group)
}

remove_outliers <- function(x) {
  x <- x[!x %in% boxplot.stats(x)$out]
  return(x)
}

S_sig <- get_sig_xcorrs(S, S_w$p)
T_sig <- get_sig_xcorrs(T, T_w$p)
M_sig <- get_sig_xcorrs(M, M_w$p)
N_sig <- get_sig_xcorrs(N, N_w$p)
L_sig <- get_sig_xcorrs(L, L_w$p)
H_sig <- get_sig_xcorrs(H, H_w$p)

df <- get_sig_xcorrs_df('S', 'talker', S_sig) %>%
  rbind(get_sig_xcorrs_df('T', 'talker', T_sig)) %>%
  rbind(get_sig_xcorrs_df('M', 'meaning', M_sig)) %>%
  rbind(get_sig_xcorrs_df('N', 'meaning', N_sig)) %>%
  rbind(get_sig_xcorrs_df('L', 'constraint', L_sig)) %>%
  rbind(get_sig_xcorrs_df('H', 'constraint', H_sig))

p <- ggplot(df, aes(x = cond, y = sig_xcorr, fill = group)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Greens") +
  geom_signif(comparisons = list(c("S", "T"), c("M", "N")), map_signif_level = TRUE) +
  ylab("cross correlations")
p
ggsave(p, filename = '../figs/xcorrs_for_sig_channels.png', width = 6, height = 3)
```

#### Get stats

```{r}
# one-sample t-test
overall_sig <- get_sig_xcorrs(overall, overall_w$p)
t.test(overall_sig)

# t-tests between levels 
t.test(T_sig, S_sig)
t.test(M_sig, N_sig)
t.test(L_sig, H_sig)
```

## Count the number of channels tracking each condition level

```{r warning=FALSE}
count_sig_chans <- function(xcorr, subs, ALT, talker = NaN, meaning = NaN, constraint = NaN) {
  cond_xcorr <- subset(xcorr,  talker = talker, meaning = meaning, constraint = constraint)
  counts <- c()
  for (sub in subs) {
    sub_xcorr <- cond_xcorr[cond_xcorr$subject_number == sub,]
    ws <- get_one_sample_wilcoxon_for_each_channel(sub_xcorr, alt = ALT)
    count <- sum(ws$p < 0.05)
    counts <- c(counts, count)
  }
  counts <- remove_outliers(counts)
  return(counts)
}

S_counts <- count_sig_chans(xcorr, subs, ALT, talker = "S")
T_counts <- count_sig_chans(xcorr, subs, ALT, talker = "T")
M_counts <- count_sig_chans(xcorr, subs, ALT, meaning = "M")
N_counts <- count_sig_chans(xcorr, subs, ALT, meaning = "N")
L_counts <- count_sig_chans(xcorr, subs, ALT, constraint = "L")
H_counts <- count_sig_chans(xcorr, subs, ALT, constraint = "H")
```

```{r warning=FALSE}
overall_counts <- count_sig_chans(xcorr, subs, ALT)
t.test(overall_counts)
```


#### Get stats

```{r}
# For talker
print(paste("Mean channel counts for same-talker: ", round(mean(S_counts), 3), sep = ''))
print(paste("sd: ", round(sd(S_counts), 3), sep = ''))
print(paste("Mean channel counts for different-talker: ", round(mean(T_counts), 3), sep = ''))
print(paste("sd: ", round(sd(T_counts), 3), sep = ''))
t.test(S_counts, T_counts)

# For meaning
print(paste("Mean channel counts for meaningful sentences: ", round(mean(M_counts), 3), sep = ''))
print(paste("sd: ", round(sd(M_counts), 3), sep = ''))
print(paste("Mean channel counts for nonsense sentences: ", round(mean(N_counts), 3), sep = ''))
print(paste("sd: ", round(sd(N_counts), 3), sep = ''))
t.test(M_counts, N_counts)

# For constraint
print(paste("Mean channel counts for low constraint sentences: ", round(mean(L_counts), 3), sep = ''))
print(paste("sd: ", round(sd(L_counts), 3), sep = ''))
print(paste("Mean channel counts for high constraint sentences: ", round(mean(H_counts), 3), sep = ''))
print(paste("sd: ", round(sd(H_counts), 3), sep = ''))
t.test(L_counts, H_counts)
```

#### Plot

```{r}
df <- data.frame(cond = rep('S', length(S_counts)), group = rep('talker', length(S_counts)), counts = S_counts) %>%
  rbind(data.frame(cond = rep('T', length(T_counts)), group = rep('talker', length(T_counts)), counts = T_counts)) %>%
  rbind(data.frame(cond = rep('M', length(M_counts)), group = rep('meaning', length(M_counts)), counts = M_counts)) %>%
  rbind(data.frame(cond = rep('N', length(N_counts)), group = rep('meaning', length(N_counts)), counts = N_counts)) %>%
  rbind(data.frame(cond = rep('L', length(L_counts)), group = rep('constraint', length(L_counts)), counts = L_counts)) %>%
  rbind(data.frame(cond = rep('H', length(H_counts)), group = rep('constraint', length(H_counts)), counts = H_counts))

p <- ggplot(df, aes(x = cond, y = counts, fill = group)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") +
  geom_signif(comparisons = list(c("S", "T")), map_signif_level = TRUE) +
  ylab("channels")
p
ggsave(p, filename = '../figs/compare_channel_counts.png', width = 6, height = 3)
```
## Count the number of channels tracking each condition

```{r warning=FALSE}
# Count the number of channels tracking each condition for each subject

count_sig_chans_two_samp <- function(xcorr, subs, cond) {
  if (cond == "talker" ) {
    cond_xcorr_1 <- subset(xcorr,  talker = "S")
    cond_xcorr_2 <- subset(xcorr,  talker = "T")
  } else if (cond == "meaning" ) {
    cond_xcorr_1 <- subset(xcorr,  meaning = "M")
    cond_xcorr_2 <- subset(xcorr,  meaning = "N")
  } else if (cond == "constraint") {
    cond_xcorr_1 <- subset(xcorr,  constraint = "L")
    cond_xcorr_2 <- subset(xcorr,  constraint = "H")
  }

  counts <- c()
  for (sub in subs) {
    if (sub == '302') {
      next
    }
    print(sub)
    sub_xcorr_1 <- cond_xcorr_1[cond_xcorr_1$subject_number == sub,]
    sub_xcorr_2 <- cond_xcorr_2[cond_xcorr_1$subject_number == sub,]
    ws <- get_two_sample_wilcoxon_for_each_channel(sub_xcorr_1, sub_xcorr_2, paired = FALSE)
    count <- sum(ws$p < 0.05, na.rm = TRUE)
    print(count)
    counts <- c(counts, count)
  }
  counts <- remove_outliers(counts)
  return(counts)
}

talker_counts <- count_sig_chans_two_samp(xcorr, subs, "talker")
meaning_counts <- count_sig_chans_two_samp(xcorr, subs, "meaning")
constraint_counts <- count_sig_chans_two_samp(xcorr, subs, "constraint")

save(talker_counts, meaning_counts, constraint_counts, file = '../data/cond_channel_counts.RData')
```

#### Get stats

```{r}
df <- data.frame(cond = rep('talker', length(talker_counts)), counts = talker_counts) %>%
  rbind(data.frame(cond = rep('meaning', length(meaning_counts)), counts = meaning_counts)) %>%
  rbind(data.frame(cond = rep('constraint', length(constraint_counts)), counts = constraint_counts))

print(paste("Mean channel counts for talker: ", round(mean(talker_counts), 3), sep = ''))
print(paste("sd: ", round(sd(talker_counts), 3), sep = ''))
print(paste("Mean channel counts for meaning: ", round(mean(meaning_counts), 3), sep = ''))
print(paste("sd: ", round(sd(meaning_counts), 3), sep = ''))
print(paste("Mean channel counts for constraint: ", round(mean(constraint_counts), 3), sep = ''))
print(paste("sd: ", round(sd(constraint_counts), 3), sep = ''))

fit <- aov(counts ~ cond, data = df)
summary(fit)
TukeyHSD(fit)
```

#### Plot

```{r}
p <- ggplot(df, aes(x = cond, y = counts, fill = cond)) +
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") +
  geom_signif(comparisons = list(c("talker", "constraint")), 
                                 map_signif_level = TRUE,
                                 annotations = c("*")) +
  ylab("channels")
p
ggsave(p, filename = '../figs/compare_condition_channel_counts.png', width = 6, height = 3)
```
#### Save everything

```{r}
# save(overall_w, one_sample_w, two_sample_w, interaction_w, interaction_two_sample_w, file = "8_wilcoxon/data/one-sided_wilcoxon_results.RData")
fname = paste("4_test_cross_correlations/data/", NORM, ALT, "_wilcoxon_results.RData", sep = "")
save(overall_w, 
     S_w, 
     T_w, 
     M_w, 
     N_w, 
     L_w, 
     H_w, 
     talker_w, 
     meaning_w, 
     constraint_w, 
     talker_L_w, 
     talker_H_w, 
     meaning_L_w,
     meaning_H_w,
     SH_w, 
     SL_w, 
     TH_w, 
     TL_w, 
     MH_w, 
     ML_w, 
     NH_w, 
     NL_w, 
     file = fname)
```
