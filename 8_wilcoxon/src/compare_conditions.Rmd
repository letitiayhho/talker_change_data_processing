---
title: "Comparing conditions"
output: html_notebook
---

```{r set up, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
setwd("/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("tibble")
library("knitr")
source("tools/functions.R")
source("8_wilcoxon/src/functions.R")

xcorr <- read.csv(file = "2_cross_correlate/data/average.csv")
```

### Wilcoxon

Identify the electrodes that track significantly for each subject in each condition (10 in different talker and 2 in same talker for subject 1, 5 in diff talker and 1 in same for subject 2 etc). Then run a test for number of active electrodes between conditions.

```{r}
count_channels <- function(data, conditions, subjects, alpha) {
  channel_labels <- paste("X", as.character(1:128), sep = "")
  df <- data.frame(subject = numeric(),
                   condition = character(),
                   count = numeric())
  for (condition in conditions) {
    condition_data <- subset(xcorr, condition = condition, keepLabels = TRUE)
    for (subject in subjects) {
      subject_data <- select(condition_data[condition_data$subject_number == subject,], all_of(channel_labels))
      w <- get_one_sample_wilcoxon(subject_data)
      count <- sum(w$p < alpha)
      df <- add_row(df, subject = subject, condition = condition, count = count)
    }
  }
  return(df)
}

conditions <- c("S", "T", "M", "N", "L", "H")
subjects <- unique(xcorr$subject_number)
loose_alpha <- count_channels(xcorr, conditions, subjects, alpha = 0.05)
strict_alpha <- count_channels(xcorr, conditions, subjects, alpha = 0.01)
mean_alpha <- count_channels(xcorr, conditions, subjects, alpha = 0.001)
```

**Talker**

```{r}
df <- data.frame(condition = character(),
                 alpha = numeric(),
                 alternative = character(),
                 V = numeric(),
                 p = numeric())

talker_loose_alpha_w <- wilcox.test(loose_alpha$count[loose_alpha$condition == "T"], 
                                    loose_alpha$count[loose_alpha$condition == "S"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.05, 
              alternative = "one-sided",
              V = talker_loose_alpha_w$statistic, 
              p = talker_loose_alpha_w$p.value)
talker_strict_alpha_w <- wilcox.test(strict_alpha$count[strict_alpha$condition == "T"], 
                                     strict_alpha$count[strict_alpha$condition == "S"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.01, 
              alternative = "one-sided",
              V = talker_strict_alpha_w$statistic,
              p = talker_strict_alpha_w$p.value)
talker_mean_alpha_w <- wilcox.test(mean_alpha$count[mean_alpha$condition == "T"], 
                                   mean_alpha$count[mean_alpha$condition == "S"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.001, 
              alternative = "one-sided",
              V = talker_mean_alpha_w$statistic, 
              p = talker_mean_alpha_w$p.value)
```

**Meaning**

```{r}
meaning_loose_alpha_w <- wilcox.test(loose_alpha$count[loose_alpha$condition == "N"], 
                                     loose_alpha$count[loose_alpha$condition == "M"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning", 
              alpha = 0.05, 
              alternative = "one-sided",
              V = meaning_loose_alpha_w$statistic, 
              p = meaning_loose_alpha_w$p.value)
meaning_strict_alpha_w <- wilcox.test(strict_alpha$count[strict_alpha$condition == "N"], 
                                      strict_alpha$count[strict_alpha$condition == "M"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning",
              alpha = 0.01, 
              alternative = "one-sided",
              V = meaning_strict_alpha_w$statistic, 
              p = meaning_strict_alpha_w$p.value)
meaning_mean_alpha_w <- wilcox.test(mean_alpha$count[mean_alpha$condition == "N"], 
                                    mean_alpha$count[mean_alpha$condition == "M"], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning", 
              alpha = 0.001, 
              alternative = "one-sided",
              V = meaning_mean_alpha_w$statistic, 
              p = meaning_mean_alpha_w$p.value)
```

**Constraint**

```{r}
constraint_loose_alpha_w <- wilcox.test(loose_alpha$count[loose_alpha$condition == "L"], 
                                        loose_alpha$count[loose_alpha$condition == "H"], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.05, 
              alternative = "two-sided",
              V = constraint_loose_alpha_w$statistic, 
              p = constraint_loose_alpha_w$p.value)
constraint_strict_alpha_w <- wilcox.test(strict_alpha$count[strict_alpha$condition == "L"], 
                                         strict_alpha$count[strict_alpha$condition == "H"], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.01, 
              alternative = "two-sided",
              V = constraint_strict_alpha_w$statistic, 
              p = constraint_strict_alpha_w$p.value)
constraint_mean_alpha_w <- wilcox.test(mean_alpha$count[mean_alpha$condition == "L"], 
                                       mean_alpha$count[mean_alpha$condition == "H"], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.001, 
              alternative = "two-sided",
              V = constraint_mean_alpha_w$statistic, 
              p = constraint_mean_alpha_w$p.value)
```

```{r}
df
```






### Permutation test

```{r}
get_coordinates <- function() {
  coordinates_fp <- file.path("../../3_channel_locations/data/average_channel_locations.sfp")
  coordinates <- read.delim(coordinates_fp, header = FALSE, sep = "", dec = ".") %>%
    .[startsWith(as.character(.$V1), "E"), ] %>%
    .[c("V2", "V3", "V4")]
  names(coordinates) <- c("x", "y", "z")
  
  # Return
  return(coordinates)
}

get_pairwise_distances <- function(coordinates) {
  distances <- as.matrix(dist(coordinates))
  
  # Return
  return(distances)
}

get_histogram_of_pairwise_distances <- function(distances) {
  sort_distances = as.vector(distances) %>%
    .[!duplicated(.)] %>%
    sort() %>%
    hist(., breaks = 50, main = "Histogram of pairwise distances")
}

get_neighboring_clusters <- function(w, max_distance, alpha, distances) {
  # Determine threshold for t-values based on specified alpha level
  # t_threshold <- qt(1-(alpha/2), df = n-1)
  
  # Identify neighboring above-threshold channels of all above-threshold channels
  clusters <- vector(mode = "list")
  for (i in 1:nrow(distances)) {
    
    # Check whether channel itself is above threshold
    if (w[i] < alpha) {
      
      # Identify all neighboring channels within the specified max_distance
      neighboring_channels = which(distances[i, ] < max_distance)
      
      # Keep above-threshold neighbors
      indexes = which(w[neighboring_channels] < alpha)
      clusters_for_one_channel = list(neighboring_channels[indexes])
      
      # Exclude channels whose only active neighbor is itself
      if (length(clusters_for_one_channel[[1]]) > 1) {
        clusters = c(clusters, clusters_for_one_channel)
      }
    } 
  }
  # Combine overlaps
  # clusters <- combine_overlaps(clusters)
  
  # Return
  return(clusters)
}

combine_overlaps <- function(clusters, min_cluster_size = 2) {
  if (length(clusters) == 0) {
    return(clusters)
  }
  
  # Compare every cluster to every other cluster
  for (i in 1:length(clusters)) {
    cluster_a <- clusters[[i]]
    
    # Loop through every cluster
    for (j in 1:length(clusters)) {
      cluster_b <- clusters[[j]]
      
      # Compare the two clusters...
      combined <- c(cluster_a, cluster_b)
      
      # If there are duplicates...
      if (TRUE %in% duplicated(combined) & (j > i)) { 
        
        # Set the original cluster into the merged cluster
        clusters[[i]] <- unique(combined)
        
        # Set the compared cluster to null
        clusters[[j]] <- 0
      }
    }
  }
  
  # Remove all clusters smaller than min_cluster_size, remove 0s
  keep = vector(mode = "list")
  for (i in 1:length(clusters)) {
    cluster = clusters[[i]]
    if (length(cluster) >= min_cluster_size) {
      keep <- c(keep, list(cluster))
    }
  }
  clusters <- keep
  
  # Return if all possible clusters are created
  if (!(TRUE %in% duplicated(unlist(clusters)))) {
    return(clusters)
  }
  
  # Recursively apply function
  return(combine_overlaps(clusters, min_cluster_size))
}

cluster_one_condition <- function(w, max_distance, alpha) {
  coordinates <- get_coordinates()
  distances <- get_pairwise_distances(coordinates)
  neighboring_clusters <- get_neighboring_clusters(w, max_distance, alpha, distances)
  clusters <- combine_overlaps(neighboring_clusters)
}

get_cluster_stats <- function(data, max_distance, alpha) {
  largest <- c()
  n_clusters <- c()
  for (i in colnames(data)) {
    clusters <- cluster_one_condition(data[[i]], max_distance, alpha)
    largest <- c(largest, max(unlist(lapply(clusters, length))))
    n_clusters <- c(n_clusters, length(clusters))
  }
  return(data.frame(condition = colnames(data), largest = largest, n_clusters = n_clusters))
}
```

#### Get observed cluster stats

```{r}
ws <- select(one_sample_w, -c("channels"))
max_distance <- 5
alpha <- 0.05

observed <- get_cluster_stats(ws, max_distance, alpha)
```

#### Get resampled cluster stats

```{r, warning=FALSE}
n_permutations <- 1000
permuted_stats <- c()
for (i in 1:n_permutations) {
  permuted_ws <- ws[sample(1:nrow(ws)),]
  permuted_stats <- rbind(permuted_stats, get_cluster_stats(permuted_ws, max_distance, alpha))
}
```

**Same talker**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "S",]$largest
obs <- observed$largest[observed$condition == "S"]
histogram(shuffled, obs, "S")
```

**Different talker**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "T",]$largest
obs <- observed$largest[observed$condition == "T"]
histogram(shuffled, obs, "T")
```

**Meaningful**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "M",]$largest
obs <- observed$largest[observed$condition == "M"]
histogram(shuffled, obs, "M")
```

**Nonsense**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "N",]$largest
obs <- observed$largest[observed$condition == "N"]
histogram(shuffled, obs, "N")
```

**Low constraint**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "L",]$largest
obs <- observed$largest[observed$condition == "L"]
histogram(shuffled, obs, "L")
```

**High constraint**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "H",]$largest
obs <- observed$largest[observed$condition == "H"]
histogram(shuffled, obs, "H")
```


