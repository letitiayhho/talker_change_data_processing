---
title: "Comparing conditions"
output: html_notebook
---

```{r set up, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
setwd("/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("tibble")
# library("ggplot2")
# library("ggpubr")
# library("kableExtra")
source("tools/functions.R")
source("8_wilcoxon/src/functions.R")

xcorr <- read.csv(file = "2_cross_correlate/data/average.csv")
```

### Wilcoxon

<!-- I was thinking if you can identify the electrodes that track significantly for each subject in each condition (10 in different talker and 2 in same talker for subject 1, 5 in diff talker and 1 in same for subject 2 etc) you can do a t-test for number of active electrodes between conditionsâ€¦ -->

```{r}
# tmp <- subset(xcorr, "LM", keepLabels = TRUE)

# One sample wilcoxon for each channel for each subject
# get_one_sample_wilcoxon_per_subject <- function(data, subjects) {
#   channel_labels <- paste("X", as.character(1:128), sep = "")
#   subjects <- unique(xcorr$subject_number)
#   ws <- c()
#   subject_number <- c()
#   for (subject in subjects) {
#     subject_data <- select(data[data$subject_number == subject,], all_of(channel_labels))
#     w <- get_one_sample_wilcoxon(subject_data)
#     w <- add_column(w, subject_number = subject, channel = c(1:128))
#     ws <- rbind(ws, w)
#   }
#   return(ws)
# }

# S <- get_one_sample_wilcoxon_per_subject(subset(xcorr, talker = "S", keep_subject_numbers = TRUE))
# T <- get_one_sample_wilcoxon_per_subject(subset(xcorr, talker = "T", keep_subject_numbers = TRUE), subjects)
# M <- get_one_sample_wilcoxon_per_subject(subset(xcorr, meaning = "M", keep_subject_numbers = TRUE), subjects)
# N <- get_one_sample_wilcoxon_per_subject(subset(xcorr, meaning = "N", keep_subject_numbers = TRUE), subjects)
# L <- get_one_sample_wilcoxon_per_subject(subset(xcorr, constraint = "L", keep_subject_numbers = TRUE), subjects)
# H <- get_one_sample_wilcoxon_per_subject(subset(xcorr, constraint = "H", keep_subject_numbers = TRUE), subjects)
```

```{r}
channel_labels <- paste("X", as.character(1:128), sep = "")
conditions <- c("S", "T", "M", "N", "L", "H")
subjects <- unique(xcorr$subject_number)

df <- data.frame(subject = numeric(),
                 condition = character(),
                 count = numeric())
for (condition in conditions) {
  condition_data <- subset(xcorr, condition = condition, keepLabels = TRUE)
  for (subject in subjects) {
    subject_data <- select(condition_data[condition_data$subject_number == subject,], all_of(channel_labels))
    w <- get_one_sample_wilcoxon(subject_data)
    count <- sum(w$p < 0.05)
    df <- add_row(df, subject = subject, condition = condition, count = count)
  }
}


# conditions <- c("S", "T", "M", "N", "L", "H")
# subjects <- unique(xcorr$subject_number)
# 
# tmp <- function(data, conditions, subjects) {
#   channel_labels <- paste("X", as.character(1:128), sep = "")
#   df <- data.frame(subject = numeric(),
#                    condition = character(),
#                    count = numeric())
#   for (condition in conditions) {
#     for (subject in subjects) {
#       subject_data <- select(tmp[tmp$subject_number == subject,], all_of(channel_labels))
#       w <- get_one_sample_wilcoxon(subject_data)
#       count <- sum(w$p < 0.05)
#       df <- add_row(df, subject = subject, condition = condition, count = count)
#     }
#   }
#   return(df)
# }
```



### Permutation test

```{r}
get_coordinates <- function() {
  coordinates_fp <- file.path("../../3_channel_locations/data/average_channel_locations.sfp")
  coordinates <- read.delim(coordinates_fp, header = FALSE, sep = "", dec = ".") %>%
    .[startsWith(as.character(.$V1), "E"), ] %>%
    .[c("V2", "V3", "V4")]
  names(coordinates) <- c("x", "y", "z")
  
  # Return
  return(coordinates)
}

get_pairwise_distances <- function(coordinates) {
  distances <- as.matrix(dist(coordinates))
  
  # Return
  return(distances)
}

get_histogram_of_pairwise_distances <- function(distances) {
  sort_distances = as.vector(distances) %>%
    .[!duplicated(.)] %>%
    sort() %>%
    hist(., breaks = 50, main = "Histogram of pairwise distances")
}

get_neighboring_clusters <- function(w, max_distance, alpha, distances) {
  # Determine threshold for t-values based on specified alpha level
  # t_threshold <- qt(1-(alpha/2), df = n-1)
  
  # Identify neighboring above-threshold channels of all above-threshold channels
  clusters <- vector(mode = "list")
  for (i in 1:nrow(distances)) {
    
    # Check whether channel itself is above threshold
    if (w[i] < alpha) {
      
      # Identify all neighboring channels within the specified max_distance
      neighboring_channels = which(distances[i, ] < max_distance)
      
      # Keep above-threshold neighbors
      indexes = which(w[neighboring_channels] < alpha)
      clusters_for_one_channel = list(neighboring_channels[indexes])
      
      # Exclude channels whose only active neighbor is itself
      if (length(clusters_for_one_channel[[1]]) > 1) {
        clusters = c(clusters, clusters_for_one_channel)
      }
    } 
  }
  # Combine overlaps
  # clusters <- combine_overlaps(clusters)
  
  # Return
  return(clusters)
}

combine_overlaps <- function(clusters, min_cluster_size = 2) {
  if (length(clusters) == 0) {
    return(clusters)
  }
  
  # Compare every cluster to every other cluster
  for (i in 1:length(clusters)) {
    cluster_a <- clusters[[i]]
    
    # Loop through every cluster
    for (j in 1:length(clusters)) {
      cluster_b <- clusters[[j]]
      
      # Compare the two clusters...
      combined <- c(cluster_a, cluster_b)
      
      # If there are duplicates...
      if (TRUE %in% duplicated(combined) & (j > i)) { 
        
        # Set the original cluster into the merged cluster
        clusters[[i]] <- unique(combined)
        
        # Set the compared cluster to null
        clusters[[j]] <- 0
      }
    }
  }
  
  # Remove all clusters smaller than min_cluster_size, remove 0s
  keep = vector(mode = "list")
  for (i in 1:length(clusters)) {
    cluster = clusters[[i]]
    if (length(cluster) >= min_cluster_size) {
      keep <- c(keep, list(cluster))
    }
  }
  clusters <- keep
  
  # Return if all possible clusters are created
  if (!(TRUE %in% duplicated(unlist(clusters)))) {
    return(clusters)
  }
  
  # Recursively apply function
  return(combine_overlaps(clusters, min_cluster_size))
}

cluster_one_condition <- function(w, max_distance, alpha) {
  coordinates <- get_coordinates()
  distances <- get_pairwise_distances(coordinates)
  neighboring_clusters <- get_neighboring_clusters(w, max_distance, alpha, distances)
  clusters <- combine_overlaps(neighboring_clusters)
}

get_cluster_stats <- function(data, max_distance, alpha) {
  largest <- c()
  n_clusters <- c()
  for (i in colnames(data)) {
    clusters <- cluster_one_condition(data[[i]], max_distance, alpha)
    largest <- c(largest, max(unlist(lapply(clusters, length))))
    n_clusters <- c(n_clusters, length(clusters))
  }
  return(data.frame(condition = colnames(data), largest = largest, n_clusters = n_clusters))
}
```

#### Get observed cluster stats

```{r}
ws <- select(one_sample_w, -c("channels"))
max_distance <- 5
alpha <- 0.05

observed <- get_cluster_stats(ws, max_distance, alpha)
```

#### Get resampled cluster stats

```{r, warning=FALSE}
n_permutations <- 1000
permuted_stats <- c()
for (i in 1:n_permutations) {
  permuted_ws <- ws[sample(1:nrow(ws)),]
  permuted_stats <- rbind(permuted_stats, get_cluster_stats(permuted_ws, max_distance, alpha))
}
```

**Same talker**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "S",]$largest
obs <- observed$largest[observed$condition == "S"]
histogram(shuffled, obs, "S")
```

**Different talker**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "T",]$largest
obs <- observed$largest[observed$condition == "T"]
histogram(shuffled, obs, "T")
```

**Meaningful**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "M",]$largest
obs <- observed$largest[observed$condition == "M"]
histogram(shuffled, obs, "M")
```

**Nonsense**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "N",]$largest
obs <- observed$largest[observed$condition == "N"]
histogram(shuffled, obs, "N")
```

**Low constraint**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "L",]$largest
obs <- observed$largest[observed$condition == "L"]
histogram(shuffled, obs, "L")
```

**High constraint**

```{r}
shuffled <- permuted_stats[permuted_stats$condition == "H",]$largest
obs <- observed$largest[observed$condition == "H"]
histogram(shuffled, obs, "H")
```


