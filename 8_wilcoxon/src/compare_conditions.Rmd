---
title: "Comparing conditions"
output: html_notebook
---

```{r set up, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
setwd("/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("tibble")
library("knitr")
library("ggplot2")
source("tools/functions.R")
source("8_wilcoxon/src/functions.R")

load("8_wilcoxon/data/wilcoxon_results.RData")
xcorr <- read.csv(file = "2_cross_correlate/data/average.csv")
```

### Wilcoxon

Identify the electrodes that track significantly for each subject in each condition (10 in different talker and 2 in same talker for subject 1, 5 in diff talker and 1 in same for subject 2 etc). Then run a test for number of active electrodes between conditions.

```{r}
count_channels <- function(data) {
  channel_labels <- paste("X", as.character(1:128), sep = "")
  df <- data.frame(subject = numeric(),
                   alpha = numeric(),
                   condition = character(),
                   count = numeric())
  for (alpha in c(0.05, 0.01, 0.001)) {
    for (condition in c("S", "T", "M", "N", "L", "H")) {
      condition_data <- subset(xcorr, condition = condition, keepLabels = TRUE)
      for (subject in unique(xcorr$subject_number)) {
        subject_data <- select(condition_data[condition_data$subject_number == subject,], all_of(channel_labels))
        w <- get_one_sample_wilcoxon(subject_data)
        count <- sum(w$p < alpha)
        df <- add_row(df, alpha = alpha, subject = subject, condition = condition, count = count)
      }
    }
  }
  return(df)
}

counts <- count_channels(xcorr)
```

```{r warning = FALSE, message = FALSE}
# checks
S <- data.frame(p = one_sample_w$S, label = "S")
T <- data.frame(p = one_sample_w$T, label = "T")
talker <- rbind(S, T)
ggplot(talker, aes(p, fill = label)) + geom_density(alpha = 0.2) + geom_vline(xintercept = 0.05)

M <- data.frame(p = one_sample_w$M, label = "M")
N <- data.frame(p = one_sample_w$N, label = "N")
meaning <- rbind(M, N)
ggplot(meaning, aes(p, fill = label)) + geom_density(alpha = 0.2) + geom_vline(xintercept = 0.05)

L <- data.frame(p = one_sample_w$L, label = "L")
H <- data.frame(p = one_sample_w$H, label = "H")
constraint <- rbind(L, H)
ggplot(constraint, aes(p, fill = label)) + geom_density(alpha = 0.2) + geom_vline(xintercept = 0.05)
```


**Channel counts**

```{r, warning=FALSE, message=FALSE}
agg <- counts %>%
  group_by(alpha, condition) %>%
  summarize(mean = mean(count), sd = sd(count))
kable(agg, digits = c(4, 0, 1, 1))
```

**Talker**

```{r warning = FALSE, message = FALSE}
df <- data.frame(condition = character(),
                 alpha = numeric(),
                 alternative = character(),
                 V = numeric(),
                 p = numeric())

talker_loose_alpha_w <- wilcox.test(counts$count[(counts$condition == "T") & (counts$alpha == 0.05)], 
                                    counts$count[(counts$condition == "S") & (counts$alpha == 0.05)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.05, 
              alternative = "one-sided",
              V = talker_loose_alpha_w$statistic, 
              p = talker_loose_alpha_w$p.value)
talker_strict_alpha_w <- wilcox.test(counts$count[(counts$condition == "T") & (counts$alpha == 0.01)], 
                                     counts$count[(counts$condition == "S") & (counts$alpha == 0.01)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.01, 
              alternative = "one-sided",
              V = talker_strict_alpha_w$statistic,
              p = talker_strict_alpha_w$p.value)
talker_mean_alpha_w <- wilcox.test(counts$count[(counts$condition == "T") & (counts$alpha == 0.001)], 
                                   counts$count[(counts$condition == "S") & (counts$alpha == 0.001)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "talker", 
              alpha = 0.001, 
              alternative = "one-sided",
              V = talker_mean_alpha_w$statistic, 
              p = talker_mean_alpha_w$p.value)
```

**Meaning**

```{r warning = FALSE, message = FALSE}
meaning_loose_alpha_w <- wilcox.test(counts$count[(counts$condition == "M") & (counts$alpha == 0.05)], 
                                    counts$count[(counts$condition == "N") & (counts$alpha == 0.05)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning", 
              alpha = 0.05, 
              alternative = "one-sided",
              V = meaning_loose_alpha_w$statistic, 
              p = meaning_loose_alpha_w$p.value)
meaning_strict_alpha_w <- wilcox.test(counts$count[(counts$condition == "M") & (counts$alpha == 0.05)], 
                                    counts$count[(counts$condition == "N") & (counts$alpha == 0.05)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning",
              alpha = 0.01, 
              alternative = "one-sided",
              V = meaning_strict_alpha_w$statistic, 
              p = meaning_strict_alpha_w$p.value)
meaning_mean_alpha_w <- wilcox.test(counts$count[(counts$condition == "M") & (counts$alpha == 0.05)], 
                                    counts$count[(counts$condition == "N") & (counts$alpha == 0.05)], 
                                    paired = TRUE,
                                    alternative = "greater")
df <- add_row(df, condition = "meaning", 
              alpha = 0.001, 
              alternative = "one-sided",
              V = meaning_mean_alpha_w$statistic, 
              p = meaning_mean_alpha_w$p.value)
```

**Constraint**

```{r warning = FALSE, message = FALSE}
constraint_loose_alpha_w <- wilcox.test(counts$count[(counts$condition == "L") & (counts$alpha == 0.05)], 
                                        counts$count[(counts$condition == "H") & (counts$alpha == 0.05)], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.05, 
              alternative = "two-sided",
              V = constraint_loose_alpha_w$statistic, 
              p = constraint_loose_alpha_w$p.value)
constraint_strict_alpha_w <- wilcox.test(counts$count[(counts$condition == "L") & (counts$alpha == 0.01)], 
                                         counts$count[(counts$condition == "H") & (counts$alpha == 0.01)], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.01, 
              alternative = "two-sided",
              V = constraint_strict_alpha_w$statistic, 
              p = constraint_strict_alpha_w$p.value)
constraint_mean_alpha_w <- wilcox.test(counts$count[(counts$condition == "L") & (counts$alpha == 0.001)], 
                                       counts$count[(counts$condition == "H") & (counts$alpha == 0.001)], paired = TRUE)
df <- add_row(df, condition = "constraint", 
              alpha = 0.001, 
              alternative = "two-sided",
              V = constraint_mean_alpha_w$statistic, 
              p = constraint_mean_alpha_w$p.value)
```

```{r}
kable(df, digits = c(0, 4, 0, 1, 3))
```






### Permutation test

```{r}
get_coordinates <- function() {
  coordinates_fp <- file.path("../../3_channel_locations/data/average_channel_locations.sfp")
  coordinates <- read.delim(coordinates_fp, header = FALSE, sep = "", dec = ".") %>%
    .[startsWith(as.character(.$V1), "E"), ] %>%
    .[c("V2", "V3", "V4")]
  names(coordinates) <- c("x", "y", "z")
  
  # Return
  return(coordinates)
}

get_pairwise_distances <- function(coordinates) {
  distances <- as.matrix(dist(coordinates))
  
  # Return
  return(distances)
}

get_histogram_of_pairwise_distances <- function(distances) {
  sort_distances = as.vector(distances) %>%
    .[!duplicated(.)] %>%
    sort() %>%
    hist(., breaks = 50, main = "Histogram of pairwise distances")
}

get_neighboring_clusters <- function(w, max_distance, alpha, distances) {
  # Determine threshold for t-values based on specified alpha level
  # t_threshold <- qt(1-(alpha/2), df = n-1)
  
  # Identify neighboring above-threshold channels of all above-threshold channels
  clusters <- vector(mode = "list")
  for (i in 1:nrow(distances)) {
    
    # Check whether channel itself is above threshold
    if (w[i] < alpha) {
      
      # Identify all neighboring channels within the specified max_distance
      neighboring_channels = which(distances[i, ] < max_distance)
      
      # Keep above-threshold neighbors
      indexes = which(w[neighboring_channels] < alpha)
      clusters_for_one_channel = list(neighboring_channels[indexes])
      
      # Exclude channels whose only active neighbor is itself
      if (length(clusters_for_one_channel[[1]]) > 1) {
        clusters = c(clusters, clusters_for_one_channel)
      }
    } 
  }
  # Combine overlaps
  # clusters <- combine_overlaps(clusters)
  
  # Return
  return(clusters)
}

combine_overlaps <- function(clusters, min_cluster_size = 2) {
  if (length(clusters) == 0) {
    return(clusters)
  }
  
  # Compare every cluster to every other cluster
  for (i in 1:length(clusters)) {
    cluster_a <- clusters[[i]]
    
    # Loop through every cluster
    for (j in 1:length(clusters)) {
      cluster_b <- clusters[[j]]
      
      # Compare the two clusters...
      combined <- c(cluster_a, cluster_b)
      
      # If there are duplicates...
      if (TRUE %in% duplicated(combined) & (j > i)) { 
        
        # Set the original cluster into the merged cluster
        clusters[[i]] <- unique(combined)
        
        # Set the compared cluster to null
        clusters[[j]] <- 0
      }
    }
  }
  
  # Remove all clusters smaller than min_cluster_size, remove 0s
  keep = vector(mode = "list")
  for (i in 1:length(clusters)) {
    cluster = clusters[[i]]
    if (length(cluster) >= min_cluster_size) {
      keep <- c(keep, list(cluster))
    }
  }
  clusters <- keep
  
  # Return if all possible clusters are created
  if (!(TRUE %in% duplicated(unlist(clusters)))) {
    return(clusters)
  }
  
  # Recursively apply function
  return(combine_overlaps(clusters, min_cluster_size))
}

cluster_one_condition <- function(w, max_distance, alpha) {
  coordinates <- get_coordinates()
  distances <- get_pairwise_distances(coordinates)
  neighboring_clusters <- get_neighboring_clusters(w, max_distance, alpha, distances)
  clusters <- combine_overlaps(neighboring_clusters)
}

get_cluster_stats <- function(data, max_distance, alpha) {
  largest <- c()
  n_clusters <- c()
  for (i in colnames(data)) {
    clusters <- cluster_one_condition(data[[i]], max_distance, alpha)
    largest <- c(largest, max(unlist(lapply(clusters, length))))
    n_clusters <- c(n_clusters, length(clusters))
  }
  return(data.frame(condition = colnames(data), largest = largest, n_clusters = n_clusters))
}
```

#### Get observed cluster stats

```{r}
# ws <- select(one_sample_w, -c("channels"))
# max_distance <- 5
# alpha <- 0.05
# 
# observed <- get_cluster_stats(ws, max_distance, alpha)
```

#### Get resampled cluster stats

```{r, warning=FALSE}
# n_permutations <- 1000
# permuted_stats <- c()
# for (i in 1:n_permutations) {
#   permuted_ws <- ws[sample(1:nrow(ws)),]
#   permuted_stats <- rbind(permuted_stats, get_cluster_stats(permuted_ws, max_distance, alpha))
# }
```

**Same talker**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "S",]$largest
# obs <- observed$largest[observed$condition == "S"]
# histogram(shuffled, obs, "S")
```

**Different talker**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "T",]$largest
# obs <- observed$largest[observed$condition == "T"]
# histogram(shuffled, obs, "T")
```

**Meaningful**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "M",]$largest
# obs <- observed$largest[observed$condition == "M"]
# histogram(shuffled, obs, "M")
```

**Nonsense**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "N",]$largest
# obs <- observed$largest[observed$condition == "N"]
# histogram(shuffled, obs, "N")
```

**Low constraint**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "L",]$largest
# obs <- observed$largest[observed$condition == "L"]
# histogram(shuffled, obs, "L")
```

**High constraint**

```{r}
# shuffled <- permuted_stats[permuted_stats$condition == "H",]$largest
# obs <- observed$largest[observed$condition == "H"]
# histogram(shuffled, obs, "H")
```


