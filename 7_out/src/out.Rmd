---
title: "Aims and figures"
author: "Letitia Ho"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("ggplot2")
library("kableExtra")
library("tuneR")
library("signal")
theme_set(theme_minimal())  
```

******

#####Fig 1. Overall tracking

**a. Sample waveform of auditory stimuli and corresponding ERP signal from channel #40 of one subject**

```{r fig.width = 6, fig.height = 3}
# Read audio file
wav_file <- readWave("~/src/talker_change_data_processing/0_set_up_and_raw_data/data/stim/original/word_saxophone.wav")

# Extract signal
signal <- wav_file@left

# Determine duration
dur <- length(signal)/wav_file@samp.rate

# Determine sample rate
fs <- wav_file@samp.rate

# Demean to remove DC offset
signal <- signal - mean(signal)

# Downsample signal to 1000 Hz
signal <- resample(signal, q = 44100, p = 1000)

# Plot waveform
plot(signal, type = 'l', xlab = 'msec', ylab = 'Amplitude', xlim = c(-99, 1500))
```

```{r fig.width = 6, fig.height = 3} 
# Read ERP
erp <- t(read.table(file = "~/src/talker_change_data_processing/7_out/data/sample_erp.txt", 
                  header = FALSE, sep = ",", dec = "."))

plot(erp, x = c(-99:1500), type = 'l', xlab = 'msec', ylab = 'Amplitude', xlim = c(-100, 1500))
```


**b**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/overall_samples.png){width=500px}

**c**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/overall.png){width=300px}

******

#####Fig 2. Condition-based differences in tracking

**a**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/conditions.png){width=500px}

**b**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/condition_differences.png){width=500px}

**c**

  ![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/talker.png){width=500px}

**d**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/meaning.png){width=500px}

**e**

![](/Users/letitiaho/src/talker_change_data_processing/4_permutation_test/figs/constraint.png){width=500px}

******

#####Fig 3. Simple linear model

**a**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/simple_linear_models/channel_1.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/simple_linear_models/channel_2.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/simple_linear_models/channel_40.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/simple_linear_models/channel_41.png){width=200px}

**b**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/1_overall_attention.png){width=500px}

******

#####Fig 4. Multilevel model

**a**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/multilevel_models/channel_1.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/multilevel_models/channel_2.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/multilevel_models/channel_40.png){width=200px}
![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/multilevel_models/channel_41.png){width=200px}

**b**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/2_same_talker.png){width=500px}

**c**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/3_different_talker.png){width=500px}

**d**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/4_difference.png){width=500px}

**e**

![](/Users/letitiaho/src/talker_change_data_processing/5_rms/figs/5_difference_histogram.png){width=300px}

