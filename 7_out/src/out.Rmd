---
title: "Aims and figures"
author: "Letitia Ho"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "/Users/letitiaho/src/talker_change_data_processing/")
#setwd("/Users/letitiaho/src/talker_change_data_processing/")
library("dplyr")
library("ggplot2")
library("kableExtra")
theme_set(theme_minimal())  
source("tools/functions.R")
```

#####Question

**How do changes in sentence meaning and talker affect cortical tracking of speech?**

####Aim 1

**Establish whether the cross-correlation is a reliable measure of the cortical tracking of speech signal**?

**Establish that the cortical tracking of speech signals varies with psychological processing**

In signal processing, the cross-correlation is a measure of similarity between two signals. Computing a cross correlation between stimuli and EEG signal may yield an indication of the extent to which cortical areas are tracking stimuli features. Three tests will be used to verify the cross-correlation as a measure of tracking. First, a permutation test randomizing stimuli-EEG pairings will indicate if the observed cross-correlation is greater than the cross-correlation between EEG signal and a randomize stimuli and due to chance. However, some channels may not significantly track the stimuli across all conditions. Channels that only track the stimuli under a single condition will not be revealed by this test. To identify channels that track only certain speech stimuli, the second permutation test will compare tracking of each condition to the tracking of randomized stimuli-EEG pairs. Evidence of condition-based tracking will also support cross correlation as a measure of meaningful stimuli processing, rather than the tracking of random noise. Lastly, to further demonstrate that channels are tracking stimuli features, the observed difference in tracking between the two levels in each condition will be compared to the difference computed between randomized EEG-stimuli pairings.

 

####Aim 2

**Establish that the psychological processing involved in tracking changes depending on 

**Examine whether the psychological processing of speech signal changes in response to stimuli demands on comprehension or perception, changing the features that are tracked**

**Examine whether changes in stimuli demands on on comprehension and perception recruit different cognitive processes, changinge the features that are tracked**


When psychological processing of the speech signal changes in response to demands on comprehension or recognition, do the features that are tracked change?

**Establish that different stimuli features recruit

**Examine whether changes in stimuli demands on on comprehension and perception recruit different cognitive processes, changinge the features that are tracked**

Investigate whether tracking depends on the cognitive demands of stimuli on comprehension and perception which recruit different cognitive processes and 


**Establish that the cortical tracking of speech signal depends on the underlying cognitive process occurring**


**Investigate whether the features being tracked depends on the cognitive demands of comprehension and perception**
this is a question of whether the cognitive demands of the stimuli change which  features are being tracked
but my original aim is more about different stimuli recruiting different cognitive processes


The analyses used to identify channels that track certain stimuli features are the same as the last two tests mentioned in Aim 1. The reason for this is that demonstrating that tracking is condition-dependent indicates that this tracking is responding to different features within the stimuli signal, represents certain cognitive processes, and is not indiscriminate stimuli following. The second permutation test described above will not only tell us that there are condition-based difference in tracking, but which stimuli are being preferentially tracked. Under an expectation-based hypothesis of speech processing it is expected that words in the different-talker condition will be less expected and therefore processed more actively by speech processing networks. Anticipated same-talker stimuli should fit the hypotheses generated by descending networks and require less processing. Under more bottom-up driven accounts of speech processing, however, the different-talker stimuli might simply be more difficult to process and tracked with less fidelity than same-talker stimuli. Since meaning and constraint aren’t differentiated on the level of the acoustic signal, it is predicted that stimuli in these conditions will not be significantly tracked compared to randomized stimuli-EEG pairings. Constraint has the additional limitation of not being a feature that unfolds in the final word, so it is unlikely that tracking will vary with degrees of sentential meaning constraint.

The third described analysis identifies channels that track the two levels of each condition differently. For example, it will reveal that channels that track same-talker stimuli more than different-talker stimuli, whereas analysis two looked simply for channels that tracked same-talker or different-talker stimuli independently. As in the second analysis, because talker differences arise at the level of the acoustic signal, it is predicted that manipulations of speaker identity will evoke different levels of tracking compared to manipulations of meaning or constraint. Additionally, the channels that show different tracking same- and different-talker stimuli may indicate the cortical networks that are responsible for responding to changes in talker and normalizing across talkers.

 

####Aim 3

**Examine whether the underlying cognitive process 

time course of tracking depends on the 

**Are there time-dependent changes in the cortical tracking of speech signal that depend on changes in cognitive processing**



**What is the time course of this tracking? [[Linking this to a psychological question as an aim is important which you suggest in the first sentence below.  Do time-dependent changes in cognitive processing of speech affect the cortical tracking of the speech signal]]**

Examining the time course of tracking will tell us whether different cognitive processes are involved in the tracking of each stimuli type. The time course of tracking will be examined by looking at the time point at which maximum cross-correlation occurs. Since a cross-correlation can be conceptualized as a measure of the overlap between two waveforms as you drag one across the other, the time at which the maximum cross-correlation occurs should indicate the time lag between stimulus presentation and its processing in the cortices. According to a motor or expectation based theory of speech processing, the unexpected stimuli should recruit more brain networks in its processing, but should not be processed at a different time to the anticipated stimuli. More bottom-up accounts, however, may predict that the additional difficulty of processing different-talker stimuli may cause a delay in processing (?). Once again, as the stimulus features that might be tracked under the meaning or constraint conditions do not predictably appear in the acoustic signal of the stimuli, there should be no significant tracking of stimuli in either condition and no difference in time lag compared to randomized stimuli-EEG pairs.

 

####Aim 4
**How is attention involved in this tracking? [[Different theories of speech perception posit different roles for attention in speech from none to substantial.  Asking how here is a bit vague… but you can state a specific hypothesis—the evidence from previous research suggests that talker changes increase demands on attention.  Does increased attention to the speech signal with a talker change improve cortical representation of speech quality? (which it should but has not been tested)]]**

The recruitment of attention in each trial is measured by the averaged RMS over all of the left superior parietal electrodes. To see whether there is a relationship between tracking and attention a simple linear model will be fitted to the data of each of the channels. The distribution of the posterior estimates of the slope between RMS and cross-correlation will indicate how much tracking varies with attention. If tracking is mediated by attention, it is predicted that the channels responsible for normalizing between talker (the channels that track same- and different-talker stimuli significantly differently) should show a stronger relationship between tracking and attention. Next, to investigate whether the recruitment of attention for tracking is different between same- and different-talker stimuli, a multilevel model will be fitted to the data with same- and different-talker as the two levels. Similar to the previous analysis, the relationship between tracking and attention in channels that are not involved in talker normalization will be used as a control. These channels should show a weaker relationship between tracking and attention than channels involved in talker normalization. If attention is used to track either same- or different-talker stimuli, the talker normalization channels should have greater posterior estimates for their slope than non-normalization channels. Lastly, and most critically, the difference between the relationship between tracking and attention in same- and different-talker trials (i.e. the difference in the slope of cross-correlation and RMS for same- and different-talker models), will indicate whether there are channels that recruit attention differently for the tracking of same- vs different-talker stimuli.

